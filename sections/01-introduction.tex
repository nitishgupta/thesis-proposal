\documentclass[main.tex]{subfiles}
\begin{document}

\section{Introduction} % 3pp
\label{sec:introduction}

% We, as humans who know one or more other natural language(s) and understand how the world functions, are able to seamlessly reason about the world using natural language all the time.
We, humans, are able to seamlessly reason about the world we live in and answer questions about it without any trouble.
Among others, one of the most common way humans gather new information and improve their understanding of the world is by asking questions and getting answers.  No wonder much work in the natural language processing community has focussed on developing question answering systems~\cite{voorhees-qa-1999,kwok-qa-2001}, i.e., getting machines to answer questions posed in natural language given some relevant background knowledge. Developing question answering systems is not only important to fill human information needs as they also provide a natural setup to probe an agent's understanding of language and the world in general.


% As a research community working towards achieving artificial intelligence, we would like to develop agents that are able to understand natural language and perform reasoning in a manner humans do.  For example, we would like machines to be able to answer questions such as \textit{``Which country has the highest per capita carbon dioxide emission?''} and \textit{``What was the longest gap between two Radiohead albums?''}.  Answering such questions goes beyond shallow lexical understanding of words; it requires an agent to understand concepts and events described in text, associate properties with them, and perform quantitative reasoning, as described linguistically by \textit{highest} and \textit{longest gap}.  In this thesis, we aim to develop models that are able to perform \textit{question answering}, i.e., map a natural language question to an answer given relevant context in a textual form.

While the scope of ``question answering'' is infinte; one can ask questions about any and everything under the sun, we focus on a setup where questions need to be answered against a passage of text that contains the relevant information.  This allows for measuring an agent's capability of understanding language while making miminal assumptions about the world knowledge that is required by the system in order to find the correct answer.
Developing models to answer such questions poses a variety of challenges -- a system needs to be able to understand the semantics of the question, represent the world being described in the context, and should be able to perform reasoning under this representation to find the answer.
% compositional nature of language and reasoning in general, specifically the question in this case.
Consider the question \textit{``Which country has the highest per capita carbon dioxide emission?''}, an agent would need to understand the semantics of the question and decompose it into multiple simpler but interrelated problems, and answer the original question by composing the solution to these sub-problems.  For example, an agent could perform the following operations --- locate the \textit{``countries''} mentioned in the context, for each one of them find their respective \textit{``per capita carbon dioxide emission''}, compute the maximum value amongst these and provide as answer the country with this emission value.
Solving these sub-problems would require the system to understand the concept of \textit{``countries''} and locate its instantiations in text, tackle various linguistic variations in which \textit{``per capita carbon dioxide emission''} of these countries might be mentioned, and perform symbolic reasoning to find the \textit{highest} value.  Similarly, the question \textit{``What was the longest gap between two Radiohead albums?''} is underspecified and poses different challenges; amongst many, it requires the system to infer that the linguistic construction \textit{``longest gap''} in the context of two \textit{albums} refers to a time-span measured in years where these years are the \textit{release dates} of \textit{Radiohead albums}.

Previous research that aimed to solve such problems can broadly be classified into three threads, semantic parsing, machine reading comprehension, and neural module networks.  Semantic parsing, rooted in formal semantics, aims to map a natural language utterance (e.g. question, instruction, etc.) to a logical meaning representation.  In the context of question answering, this meaning representation is usually an \textit{executable logical form}, that can be thought of as a program, which can be executed against some representation of the world to get the desired output.  Explicit modeling of \textit{compositionality} in the meaning representation makes semantic parsing a desirable approach to solve such problems.
% i.e., the meaning of an expression can be recursively defined using the meaning of its subexpressions.
% Modeling compositionality explicitly should help a model deal with the productivity and systematicity of natural language.
% In the context of machine learning, the logical form provides a rationale to the final outcome predicted by the model which again makes semantic parsing a good choice to develop such question answering systems.
One major drawback of semantic parsing is that it bypasses the imporant questions of learning how to represent the world (say, a text passage), and hence its usage is limited to modalities where execution can be determinisitically defined (e.g. structured databases).
Over the last decade, with the advent of large-scale neural network models for natural language processing, black-box neural models for question answering have emerged \cite{bidaf-2016,qanet-2018,bert-2018}.
% that map a question string to an answer string conditioned on some relevant context.
Such models exploit the expressive representational capacity of neural networks to learn a non-explicit \textit{``meaning representation''} of language, expressed as continuous vectors, and find the answer without resorting to explicit compositional semantics.  While such models have shown extremely good performance on standard benchmarks for machine reading comprehension, there have also been several studies showcasing the brittleness of these approaches~\cite{adversarial-squad-2017,sears-2018,pathologies-nlp-2018}.  Furthermore, the \textit{black-box} nature of such models makes it difficult to interpret its decision making process.
Recently proposed neural module networks (NMNs;~\newcite{nmn-2016}) tries to combine the best of both worlds, the explicit modeling of question semantics in terms of a formal meaning representation with the power of neural networks for representation learning.  Like semantic parsing, it maps the question in to a logical form, but here this logical form is composed of predicates that are not fixed functions but rather functions with learnable parameters (or modules).  These modules learn to percieve the context and solve different basic understanding tasks and can be composed to perform higher-order reasoning.  While extremely promising, this approach has mainly been applied to question answering in synthetic visual domains. % and has not been applied to reasoning against text as context.
% This approach decomposes the problem of learning a highly complex mapping function into the problem of learning an explicit meaning representation of the utterance and learning multiple primitive task predictors.

% One key issue with such approaches is that they treat question answering as a problem of learning a single function to map questions and contexts to answers.  However, as decribed in the earlier, it is perhaps useful to treat question answering as a multitask problem where each instance requires solving several interrelated problems.

\subsection{Overview of current work}
In this thesis, we aim to borrow ideas from these research directions and take steps towards developing models that are able to perform reasoning over text.  Specifically, we would like the models we design to have the following desiderata; (a) the model should explicitly model compositionality in language and reasoning, i.e., the model structure should imitate the linguistic and reasoning structure closely, (b) the model's decision making process should be interpretable to some level that allows for understanding the model behavior and opens up possibilities for debugging, (c) the model should be modular, i.e. composed of operators that are resuable; this should allow for transfer of supervision and primitive reasoning capability across various domains and tasks.

In Chaper 2, we present a neural module network (NMN) for answering compositional questions that require multiple steps of reasoning against text as context.  We introduce modules that are capable of performing both shallow reasoning over a paragraph of text and symbolic reasoning (such as arithmetic, sorting, counting) over numbers and dates in a probabilistic and differentiable manner.  Our model which builds off of NMNs fulfils all desiderata as explained above but learning such a model using only weak question-answer supervision is extremely challenging.  We additionally show how problem decomposition allows for using auxiliary objectives to aid learning.

While such models are inherently interpretable by the means of the question program and the intermediate outputs of program execution, we show in Chapter 3 that learning from end-goal supervision does not guarantee that the modules outputs are faithful to the logical meaning representation of the question.  We find that due to the extreme expressivity of neural models, the modules do not learn their intended behavior when the only learning supervision is from the end-task.  We outline few methods to alleviate this issue; providing auxiliary supervision for module outputs, designing the formal language such that expected linguistic phenonmena have corresponding semantic predicates, and providing the correct inductive bias to the model through careful module architecture design.


% For parsing the question into a logical form, we use what has become standard practice now, Seq2Seq~\cite{seq2seq-2014,seq2seq-attn-2015} models. These models have shown to perform extremely well as semantic parsers in various domains~\cite{dong-lapata-2016,krishnamurthy-wikitable-2017,iyer-code-2018}, but it has also been shown that such parser can fail to generalize in surprising ways~\cite{text2sql-2018,sys-generalization-2018}.
For question parsing we use Seq2Seq~\cite{seq2seq-2014,seq2seq-attn-2015} models. These have become standard practice to parse natural language utterances into logical forms~\cite{dong-lapata-2016,krishnamurthy-wikitable-2017,iyer-code-2018} even though it has also been shown that these parsers can fail to generalize in surprising ways~\cite{text2sql-2018,sys-generalization-2018}.
In Chapter 4, we present an approach for semantic parsing that resembles Montague semantics~\cite{montague-semantics}, in which a tree of interpretable expressions is built over the utterance.  The nodes in the parse tree are combined using semantic-composition functions (modules) whose parameters are jointly learned with the parser.  Though similar in essence to NMNs, by building a parse-tree over the input utterance, this approach imposes a linguistically motivated independence assumption where phrases are interpreted independently from their surrounding words.  Such inductive bias helps the model generalize to interpreting phrases in novel contexts.  This work provides an evidence in a synthetically constructed knowledge-graph domain that it is possible to jointly learn semantic-composition functions and a semantic parser using just utterance-denotation as supervision.

\subsection{Overview of future work}

Our contributions so far have focussed on developing a compositional and modular model for question answering against text that is capable of performing symbolic reasoning. The ideas presented until now can be extended and improved in various ways. For the rest of the thesis we plan to focus on these directions.

\paragraph{Extending reasoning capabilities} - The model we present in Chapter 1 has limited capability in terms of handling linguistic constructions that require a symbolic interpretation.  For example, the modules we currently define cannot handle determiners such as \textit{``most''} in \textit{``Did Bernie Sanders win the most votes?''} or \textit{``more than half''} in \textit{``Who scored more than half the runs?''}. We would like to push forward in this direction and design differentiable modules such that our model is capable of handling a diverse range of operators (for example, such generalized quantifiers).

\paragraph{Transfer learning} - One key advantage of modular models is the capability to reuse modules in novel contexts, domains, and tasks. We would like to pursue this direction and and as a starting step try to develop a single question answering system that can be trained and evaluated on multiple benchmarks silmultaneously, for example, on datasets in the Open Reading Benchmark~(ORB;~\newcite{dua-orb-2019}).

\paragraph{Systematic Generalization} -
% While several machine learning models show extremely good performance on standard iid-test splits, it has been shown that these models often fail to \word{characterize} the underlying linguistic phenomenon and fail to generalize in surprising ways.
Though it seems natural that explicitly compositional models should be able to generalize better than black-box models, several works~\cite{sys-generalization-2018,closure-generalization-2020} have shown that it is not necessarily true. We would like to investigate this in the context of questions we tackle and improve model generalization on recently introduced stress test-sets~\cite{contrast-sets-2020} and challenging evaluation settings~\cite{text2sql-2018}.


% King of arbit.


% How do we computationally represent the meaning of language?
% How do we automatically produce these representations from text?

% decisions made a priori about how to represent the world are necessarily lossy

% logical meaning representations

% the structure of the associated program/meaning representation reflects the linguistic structure of question

% formal representations of language

% model structure imitates reasoning and/or linguistic structure

% structured representations of language

% SP has bypassed questions of learning how to represent the world

% can formal (compositional) representations of sentence meaning help us learn reusable operators for perception and reasoning

% What sorts of linguistic phenomena should be explicitly articulated in logical meaning representations, and what distinctions should be left to learning

% automatic discovery of reusable discrete operators for perception and reasoning remains a major challenge -- mike lewis work

% Rather than thinking of question answering as a problem of learning a single function to map from questions and contexts to answers, it’s perhaps useful to think of it as a highly-multitask learning setting, where each problem instance is associated with a novel task, and the identity of that task is expressed only noisily in language

\biblio

\end{document}
